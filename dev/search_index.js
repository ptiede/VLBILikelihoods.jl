var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = VLBILikelihoods","category":"page"},{"location":"#VLBILikelihoods","page":"Home","title":"VLBILikelihoods","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for VLBILikelihoods.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [VLBILikelihoods]","category":"page"},{"location":"#VLBILikelihoods.AbstractVLBIDistributions","page":"Home","title":"VLBILikelihoods.AbstractVLBIDistributions","text":"abstract type AbstractVLBIDistributions <: Distributions.Distribution{Distributions.Multivariate, Distributions.Continuous}\n\nAbstract type that detail that the distribution is the likelihood for some VLBI dataproduct. One key difference between an AbstractVLBIDistribution and a regular Distributions.jl one is that by default we expect on the fields of the struct defining the distribution to be lognorm which gives the log-normalization constant for the distribution.\n\nThis prevents the model from constantly having to compute the log-normalization constant everytime the density is evaluated, which is often the most expensive part of the computation.\n\nTo implement a AbstractVLBIDistributions a user then just needs to implement\n\nunormed_logdensity(d::AbstractVLBIDistribution, x)\n\nwhich takes in the new distribution type d and the point you wish to evaluate the density at. Internally VLBILikelihood add in the normalization constant.\n\nAdditionally, if the user wishes to change this behavior they can also overload the lognorm function to opt-out of storing the normalization constant in the struct.\n\n\n\n\n\n","category":"type"},{"location":"#VLBILikelihoods.AmplitudeLikelihood-Tuple{AbstractVector, AbstractVector}","page":"Home","title":"VLBILikelihoods.AmplitudeLikelihood","text":"AmplitudeLikelihood(μ, Σ::Union{AbstractVector, AbstractMatrix})\n\nForms the likelihood for amplitudes from the mean vector μ and the covariance matrix Σ. If Σ is vector or a diagonal matrix then we assume that the argument is the diagonal covariance matrix. If Σ is a full matrix then we assume that a dense covariance was passed\n\nNotes\n\nWe do no processing to the data, i.e. the mean μ is not-debiased anywhere.\n\nWarning\n\nThis likelihood will be significantly biased from the true Rice distribution for data points with SNR = μ/Σ < 2. If this matter significantly for you, we recommend that you consider fitting pure complex visibilities instead.\n\n\n\n\n\n","category":"method"},{"location":"#VLBILikelihoods.ClosurePhaseLikelihood","page":"Home","title":"VLBILikelihoods.ClosurePhaseLikelihood","text":"ClosurePhaseLikelihood(μ, Σ)\n\nConstruct the Gaussian approximate closure phase likelihood distribution. The distribution used here is not the exact distribution for closure phases since this becomes quite complicated (especially for correlated covariances). For our approximation we take the Gaussian around the complex exponential of the phase, that is the unormalized likelihood is given by\n\n    logmathcalL = -frac12(e^itheta - e^imu)^TSigma^-1(e^itheta - e^imu)\n\nIf Σ is diagonal then this reduces to a bunch of independent Von Mises distributions, and if Σ is dense, this becomes a complicated multi-variate extension of the Von Mises distribution[1].\n\nParameters\n\nμ: The mean closure phase, which is usually computed from some VLBI model\nΣ: The measurement covariance matrix, which is usually computed directly from the data.      Note that Σ can either be a matrix or a vector. If Σ is a vector then we interpret      Σ to represent the diagonal of the covariance matrix.\n\nWarning\n\nNote that for the dense Σ, the likelihood is not normalized properly since the normalization is not analytically tractable. This is not a problem for sampling since the normalizing constant does not depend on μ so it does not usually impact parameter estimation. However, if you are including terms that modify the covariance Σ then this likelihood is wrong and could give biased results. If you want to fit noise terms in Σ please either use the diagonal approximation to the likelihood, or better yet fit complex visibilities directly.\n\n[1]: This distribution is defined on the n torus where n is the number of closure phases.\n\n\n\n\n\n","category":"type"},{"location":"#VLBILikelihoods.ComplexVisLikelihood","page":"Home","title":"VLBILikelihoods.ComplexVisLikelihood","text":"ComplexVisLikelihood(μ::AbstractVector{<:Complex}, Σ::AbstractVector{<:Real})\n\nCreates the complex visibility likelihood distribution which is a diagonal complex Gaussian with strictly real covariance matrix.\n\nParamters\n\nμ: The mean complex visibility, which is usually computed from some VLBI model\nΣ: The measurement covariance matrix, which is usually computed directly from the data.      Note that Σ must be a real element vector and is interpreted at the diagonal of the      covariance matrix.\n\n\n\n\n\n","category":"type"},{"location":"#VLBILikelihoods.lognorm-Tuple{VLBILikelihoods.AbstractVLBIDistributions}","page":"Home","title":"VLBILikelihoods.lognorm","text":"lognorm(d::AbstractVLBIDistributions)\n\nCompute the log-normalizatoin constant of the distribution d.\n\n\n\n\n\n","category":"method"}]
}
